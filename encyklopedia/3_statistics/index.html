<!DOCTYPE html>
<html lang="en" class="js csstransforms3d">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="generator" content="Hugo 0.91.0" />
    <meta name="description" content="Describing statistical methods">
<meta name="author" content="Lukasz Rabalski">

    <link rel="icon" href="/blog/images/favicon.png" type="image/png">

    <title>Statistics :: Lukasz Rabalski website 2</title>

    
    <link href="/blog/css/nucleus.css?1640713644" rel="stylesheet">
    <link href="/blog/css/fontawesome-all.min.css?1640713644" rel="stylesheet">
    <link href="/blog/css/hybrid.css?1640713644" rel="stylesheet">
    <link href="/blog/css/featherlight.min.css?1640713644" rel="stylesheet">
    <link href="/blog/css/perfect-scrollbar.min.css?1640713644" rel="stylesheet">
    <link href="/blog/css/auto-complete.css?1640713644" rel="stylesheet">
    <link href="/blog/css/atom-one-dark-reasonable.css?1640713644" rel="stylesheet">
    <link href="/blog/css/theme.css?1640713644" rel="stylesheet">
    <link href="/blog/css/tabs.css?1640713644" rel="stylesheet">
    <link href="/blog/css/hugo-theme.css?1640713644" rel="stylesheet">
    
    

    <script src="/blog/js/jquery-3.3.1.min.js?1640713644"></script>

    <style>
      :root #header + #content > #left > #rlblock_left{
          display:none !important;
      }
      
    </style>
    
  </head>
  <body class="" data-url="/blog/encyklopedia/3_statistics/">
    <nav id="sidebar" class="showVisitedLinks">



  <div id="header-wrapper">
    <div id="header">
      <a id="logo" href='/'>

<svg id="grav-logo" version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
	width="100%" height="100%"  viewBox="0 0 285.1 69.9" xml:space="preserve">
<g>
	<path d="M35,0c9.6,0,17.9,3.4,24.7,10.3c6.8,6.8,10.3,15,10.3,24.7c0,9.7-3.4,17.9-10.3,24.7c-6.8,6.8-15,10.3-24.7,10.3
		c-9.7,0-17.9-3.4-24.7-10.3C3.4,52.8,0,44.6,0,34.9c0-9.6,3.4-17.9,10.3-24.7C17.1,3.4,25.3,0,35,0z M22.3,63.7
		c0.3-7.4,0.3-14.7,0-22.1c-2.1-0.4-4-0.4-5.9,0c-0.2,0.8-0.2,2.5-0.1,4.9c0.1,2.3,0,3.9-0.3,4.8c-1.7-0.6-2.7-2.1-3.1-4.6
		c-0.1-0.7-0.1-3.3-0.1-8c0-14.5-0.1-23-0.3-25.6c-3.6,4.1-5.6,7-5.9,8.5v10.9c0,4.5,0.1,8.1,0.2,10.9c0,0.4,0,1.3-0.1,2.8
		c-0.1,1.2,0,2.1,0.1,2.6c0.1,0.6,1.1,2.1,2.8,4.7C13.2,58.7,17.5,62.2,22.3,63.7z M44.6,65.4c0.3-5,0.2-12.9-0.1-23.6
		c-2.1-0.3-4.1-0.3-5.9,0c-0.2,2-0.2,5.1-0.1,9.5c0.1,4.3,0,7.5-0.1,9.5c-2.9,0.4-5,0.3-6.2-0.1c-0.2-5.6-0.2-15.2-0.1-28.7
		c0.1-12.4,0-21.8-0.3-28.3c-2.4,0.1-4.3,0.6-5.7,1.3c-0.1,7.7-0.2,17.7-0.1,30.1c0,16.5,0,26.6,0,30.3c2.3,1.1,5.4,1.7,9.4,1.7
		C38.9,66.9,42.1,66.4,44.6,65.4z M48.1,64.1c9.7-4.6,15.7-12,18-22.2c-1.8-0.2-3.8-0.3-6.1-0.3c-1.6,3.9-2.6,6.3-3.2,7.2
		c-1.1,1.7-2,2.5-2.7,2.5C54,46,54,39.1,54,30.5c0-11.5,0-18.4,0-20.9c-1.4-1.4-3.3-2.5-5.7-3.4C48.1,6.3,48,6.4,48,6.7
		c0,3.5,0,13.1,0,28.8C47.9,47.2,48,56.8,48.1,64.1z"/>
</g>
<g>
	<path d="M116.6,51.3h-29c-0.5,0-0.9-0.1-1.3-0.2c-0.4-0.2-0.7-0.4-1-0.7c-0.3-0.3-0.5-0.6-0.7-1c-0.2-0.4-0.2-0.8-0.2-1.3V16.3h6.3
		V45h25.8V51.3z"/>
	<path d="M154.8,51.3h-22.9c-0.9,0-1.8-0.2-2.9-0.5c-1-0.3-2-0.8-2.9-1.5c-0.9-0.7-1.6-1.6-2.2-2.8c-0.6-1.1-0.9-2.5-0.9-4.2V19.5
		c0-0.4,0.1-0.9,0.2-1.2c0.2-0.4,0.4-0.7,0.7-1c0.3-0.3,0.6-0.5,1-0.7c0.4-0.2,0.8-0.2,1.3-0.2h28.6v6.3h-25.4v19.8
		c0,0.8,0.2,1.5,0.7,1.9s1.1,0.7,1.9,0.7h22.9V51.3z M151.9,37h-20v-6.4h20V37z"/>
	<path d="M197.3,51.3H191v-8.6h-22.3v8.6h-6.3V33.8c0-2.6,0.4-4.9,1.3-7.1s2.1-4,3.7-5.5c1.6-1.5,3.4-2.8,5.5-3.6
		c2.1-0.9,4.5-1.3,7-1.3h14.3c0.4,0,0.9,0.1,1.2,0.2c0.4,0.2,0.7,0.4,1,0.7s0.5,0.6,0.7,1c0.2,0.4,0.2,0.8,0.2,1.2V51.3z
		 M168.7,36.4H191V22.6h-11.2c-0.2,0-0.6,0-1.2,0.1c-0.6,0.1-1.4,0.2-2.2,0.4c-0.8,0.2-1.7,0.6-2.6,1c-0.9,0.5-1.8,1.1-2.5,2
		c-0.8,0.8-1.4,1.9-1.9,3.1c-0.5,1.2-0.7,2.8-0.7,4.5V36.4z"/>
	<path d="M241.7,28.1c0,1.4-0.2,2.7-0.5,3.9c-0.4,1.1-0.8,2.1-1.5,3c-0.6,0.9-1.3,1.6-2.1,2.2c-0.8,0.6-1.6,1.1-2.5,1.5
		c-0.9,0.4-1.8,0.7-2.6,0.9c-0.9,0.2-1.7,0.3-2.5,0.3l13.3,11.5h-9.8l-13.2-11.5h-4.6v-6.3H230c0.8-0.1,1.5-0.2,2.2-0.5
		c0.7-0.3,1.2-0.6,1.7-1.1c0.5-0.5,0.9-1,1.1-1.6c0.3-0.6,0.4-1.4,0.4-2.2v-4c0-0.4,0-0.6-0.1-0.8c-0.1-0.2-0.2-0.3-0.3-0.4
		c-0.1-0.1-0.3-0.1-0.4-0.2c-0.2,0-0.3,0-0.4,0h-20.9v28.7h-6.3V19.5c0-0.4,0.1-0.9,0.2-1.2c0.2-0.4,0.4-0.7,0.7-1
		c0.3-0.3,0.6-0.5,1-0.7c0.4-0.2,0.8-0.2,1.3-0.2H234c1.4,0,2.6,0.3,3.6,0.8s1.8,1.2,2.4,1.9c0.6,0.8,1,1.6,1.3,2.5
		c0.3,0.9,0.4,1.7,0.4,2.5V28.1z"/>
	<path d="M285.1,48.6c0,0.5-0.1,0.9-0.3,1.3c-0.2,0.4-0.4,0.7-0.7,1c-0.3,0.3-0.6,0.5-1,0.7c-0.4,0.2-0.8,0.2-1.2,0.2
		c-0.4,0-0.8-0.1-1.2-0.2c-0.4-0.1-0.8-0.4-1.1-0.7l-23.2-24.2v24.7h-6.3V19c0-0.7,0.2-1.2,0.5-1.8c0.4-0.5,0.8-0.9,1.4-1.2
		c0.6-0.2,1.2-0.3,1.9-0.2s1.2,0.4,1.6,0.9l23.2,24.2V16.3h6.3V48.6z"/>
</g>
</svg>

</a>

    </div>
    
        <div class="searchbox">
    <label for="search-by"><i class="fas fa-search"></i></label>
    <input data-search-input id="search-by" type="search" placeholder="Search...">
    <span data-search-clear=""><i class="fas fa-times"></i></span>
</div>

<script type="text/javascript" src="/blog/js/lunr.min.js?1640713644"></script>
<script type="text/javascript" src="/blog/js/auto-complete.js?1640713644"></script>
<script type="text/javascript">
    
        var baseurl = "https:\/\/rombix92.github.io\/blog\/";
    
</script>
<script type="text/javascript" src="/blog/js/search.js?1640713644"></script>

    
  </div>
  

    <div class="highlightable">
    <ul class="topics">

        
          
          




 
  
    
    <li data-nav-id="/blog/encyklopedia/" title="Encyklopedia" class="dd-item
        parent
        
        
        ">
      <a href="/blog/encyklopedia/">
          Encyklopedia
          
            <i class="fas fa-check read-icon"></i>
          
      </a>
      
      
        <ul>
          
          
          

        
          
            
            




 
  
    
      <li data-nav-id="/blog/encyklopedia/1_r_markdown/" title="R_Markdown" class="dd-item ">
        <a href="/blog/encyklopedia/1_r_markdown/">
        R_Markdown
        <i class="fas fa-check read-icon"></i>
        </a>
    </li>
     
  
 

            
          
            
            




 
  
    
      <li data-nav-id="/blog/encyklopedia/2_data_grapling/" title="Data Exploration" class="dd-item ">
        <a href="/blog/encyklopedia/2_data_grapling/">
        Data Exploration
        <i class="fas fa-check read-icon"></i>
        </a>
    </li>
     
  
 

            
          
            
            




 
  
    
      <li data-nav-id="/blog/encyklopedia/3_statistics/" title="Statistics" class="dd-item active">
        <a href="/blog/encyklopedia/3_statistics/">
        Statistics
        <i class="fas fa-check read-icon"></i>
        </a>
    </li>
     
  
 

            
          
        
        </ul>
      
    </li>
  
 

          
          




 
  
    
    <li data-nav-id="/blog/projects/" title="Projects" class="dd-item
        
        
        
        ">
      <a href="/blog/projects/">
          Projects
          
            <i class="fas fa-check read-icon"></i>
          
      </a>
      
      
        <ul>
          
          
          

        
          
            
            




 
  
    
      <li data-nav-id="/blog/projects/2020-12-01-r-rmarkdown/" title="Grow of Metropolis" class="dd-item ">
        <a href="/blog/projects/2020-12-01-r-rmarkdown/">
        Grow of Metropolis
        <i class="fas fa-check read-icon"></i>
        </a>
    </li>
     
  
 

            
          
        
        </ul>
      
    </li>
  
 

          
        
    </ul>

    
    
      <section id="shortcuts">
        <h3>More</h3>
        <ul>
          
              <li>
                  <a class="padding" href="https://github.com/Rombix92"><i class='fab fa-fw fa-github'></i> GitHub repo</a>
              </li>
          
              <li>
                  <a class="padding" href="https://rombix92.github.io/blog/tags"><i class='fas fa-tags'></i> Tags</a>
              </li>
          
        </ul>
      </section>
    

    
    <section id="prefooter">
      <hr/>
      <ul>
      

      
        <li><a class="padding" href="#" data-clear-history-toggle=""><i class="fas fa-history fa-fw"></i> Clear History</a></li>
      
      </ul>
    </section>
    
    <section id="footer">
      <center>
    
    <a class="github-button" href="https://github.com/matcornic/hugo-theme-learn/archive/master.zip" data-icon="octicon-cloud-download" aria-label="Download matcornic/hugo-theme-learn on GitHub">Download</a>

    
    <a class="github-button" href="https://github.com/matcornic/hugo-theme-learn" data-icon="octicon-star" data-show-count="true" aria-label="Star matcornic/hugo-theme-learn on GitHub">Star</a>

    
    <a class="github-button" href="https://github.com/matcornic/hugo-theme-learn/fork" data-icon="octicon-repo-forked" data-show-count="true" aria-label="Fork matcornic/hugo-theme-learn on GitHub">Fork</a>

    <p>Built with <a href="https://github.com/matcornic/hugo-theme-learn"><i class="fas fa-heart"></i></a> from <a href="https://getgrav.org">Grav</a> and <a href="https://gohugo.io/">Hugo</a></p>
</center>

<script async defer src="https://buttons.github.io/buttons.js"></script>

    </section>
  </div>
</nav>




        <section id="body">
        <div id="overlay"></div>
        <div class="padding highlightable">
              
              <div>
                <div id="top-bar">
                
                
                <div id="breadcrumbs" itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb">
                    <span id="sidebar-toggle-span">
                        <a href="#" id="sidebar-toggle" data-sidebar-toggle="">
                          <i class="fas fa-bars"></i>
                        </a>
                    </span>
                  
                  <span id="toc-menu"><i class="fas fa-list-alt"></i></span>
                  
                  <span class="links">
                 
                 
                    
          
          
            
            
          
          
            
            
          
          
            <a href='/blog/'>Lukasz Rabalski website</a> > <a href='/blog/encyklopedia/'>Encyklopedia</a> > Statistics
          
        
          
        
          
        
                 
                  </span>
                </div>
                
                    <div class="progress">
    <div class="wrapper">

    </div>
</div>

                
              </div>
            </div>
            
        <div id="head-tags">
        
        </div>
        
        <div id="body-inner">
          
            <h1>
              
              Statistics
            </h1>
          

        



<script src="/blog/rmarkdown-libs/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#logistic-regression">Logistic Regression</a>
<ul>
<li><a href="#matematyczna-interpretacja-modelu">Matematyczna interpretacja modelu</a></li>
<li><a href="#graficzna-interpretacja-modelu">Graficzna interpretacja modelu</a></li>
</ul></li>
<li><a href="#bayesian-statistics---introduction">Bayesian Statistics - Introduction</a>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#priors">Priors</a></li>
<li><a href="#contrasts-and-comparison">Contrasts and comparison</a></li>
<li><a href="#dealing-with-2-parameter-model">Dealing with 2 parameter model</a></li>
<li><a href="#automatisation---best-package">Automatisation - BEST package</a></li>
<li><a href="#conclusions">Conclusions</a></li>
</ul></li>
<li><a href="#bayesian-statistics---intermediate">Bayesian Statistics - Intermediate</a>
<ul>
<li><a href="#likelihood">Likelihood</a></li>
<li><a href="#posterior">Posterior</a></li>
</ul></li>
</ul>
</div>

<div id="logistic-regression" class="section level2">
<h2>Logistic Regression</h2>
<p><a href="https://bookdown.org/yihui/rmarkdown/html-document.html"><em>Markdown
Tutorial</em></a></p>
<div id="matematyczna-interpretacja-modelu" class="section level3">
<h3>Matematyczna interpretacja modelu</h3>
<p>Quiz correct answers: d. Hint: <code>Remember</code>, the coefficient in a logistic
regression model is the expected increase in the log odds given a one
unit increase in the explanatory variable.</p>
<table>
<thead>
<tr class="header">
<th align="right">Survived</th>
<th align="right">Fare</th>
<th align="right">Fare_log</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">7.2500</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">71.2833</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">7.9250</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">53.1000</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="right">0</td>
<td align="right">8.0500</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">0</td>
<td align="right">8.4583</td>
<td align="right">2</td>
</tr>
</tbody>
</table>
<p>Wyliczanie modelu logistycznego.</p>
<pre class="r"><code>model &lt;- glm(data=df_titanic, Survived ~ Fare_log, family = &#39;binomial&#39;)

tidy(model)  %&gt;% kable(caption=&#39;Table 1. Summary statistics for logistic regression model&#39;)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-3">Table 1: </span>Table 1. Summary statistics for logistic regression model</caption>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">-2.3337286</td>
<td align="right">0.2452271</td>
<td align="right">-9.516601</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">Fare_log</td>
<td align="right">0.6442428</td>
<td align="right">0.0792358</td>
<td align="right">8.130706</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>Model wyliczany jest zgodnie z ponizsza formula
<img src="graph/model_logistic_regression.jpg" id="id" class="class" style="width:50.0%;height:50.0%" /></p>
<p>dlategp by otrzymac oszacowania paraemtrow w formie ich wpływu na odds
musimy je poddać działaniu exp()</p>
<p><img src="graph/odds.jpg" class="class" style="width:50.0%;height:50.0%" /></p>
<pre class="r"><code>coef(model)</code></pre>
<pre><code>## (Intercept)    Fare_log 
##  -2.3337286   0.6442428</code></pre>
<pre class="r"><code>#Tak przemnozone wspolczynniki interpretujemy nastepujaco:
#  o ile % wzrosnie odds wystapienia zdarzenia jezeli wzrosnie nam wartosc predyktora o 1

exp(coef(model))</code></pre>
<pre><code>## (Intercept)    Fare_log 
##  0.09693365  1.90454431</code></pre>
<p>Ponizej w sposob matematyczny pokazuje ze to wlasnie oznacza
interpretacja wzrostu parametra stajacego przy predyktorze.</p>
<pre class="r"><code>df_aug &lt;- augment(model, type.predict = &quot;response&quot;) # without response argument, the fitted value will be on log-odds scale

p3 = df_aug$.fitted[df_aug$Fare_log==3][1]
p2 = df_aug$.fitted[df_aug$Fare_log==2][1]

x &lt;- round(p3/(1-p3)/(p2/(1-p2)),5)

# i sprawdzenie czy dobrze rozumiem zależnosc
x1&lt;-round(exp(coef(model))[&#39;Fare_log&#39;],5)
x1==x</code></pre>
<pre><code>## Fare_log 
##     TRUE</code></pre>
<p>Prob for Fare_log = 2 was equal to 0.2601396 while for Fare_log = 3 was
equal to 0.401072. The odds increase by 1.90454. The same what model results
suggests -&gt; 1.90454.</p>
<p>Quiz</p>
<p>The fitted coefficient from the medical school logistic regression model
is 5.45. The exponential of this is 233.73.</p>
<p>Donald’s GPA is 2.9, and thus the model predicts that the probability of
him getting into medical school is 3.26%. The odds of Donald getting
into medical school are 0.0337, or—phrased in gambling terms—29.6:1.
If Donald hacks the school’s registrar and changes his GPA to 3.9, then
which of the following statements is FALSE:</p>
<p>Possible Answers</p>
<ol style="list-style-type: lower-alpha">
<li>His expected odds of getting into medical school improve to 7.8833
(or about 9:8).</li>
<li>His expected probability of getting into medical school improves to
88.7%.</li>
<li>His expected log-odds of getting into medical school improve by
5.45.</li>
<li>His expected probability of getting into medical school improves to
7.9%.</li>
</ol>
<p>Correct answers on the top of the page</p>
</div>
<div id="graficzna-interpretacja-modelu" class="section level3">
<h3>Graficzna interpretacja modelu</h3>
<p><img src="/blog/encyklopedia/3_Statistics_files/figure-html/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<p><img src="graph/log_odds.jpg" class="class" style="width:50.0%;height:50.0%" /></p>
<p><img src="graph/comparison_of_3_scales.jpg" class="class" style="width:50.0%;height:50.0%" /></p>
<pre class="r"><code>df_aug %&gt;% mutate(Survived_hat=round(.fitted)) %&gt;%
  select(Survived, Survived_hat) %&gt;% table</code></pre>
<pre><code>##         Survived_hat
## Survived   0   1
##        0 462  83
##        1 219 123</code></pre>
<pre class="r"><code>#Out of sample predictions
DiCaprio&lt;-data.frame(Fare_log=1)
augment(model, newdata = DiCaprio, type.predict = &#39;response&#39;)</code></pre>
<pre><code>## # A tibble: 1 × 2
##   Fare_log .fitted
##      &lt;dbl&gt;   &lt;dbl&gt;
## 1        1   0.156</code></pre>
</div>
</div>
<div id="bayesian-statistics---introduction" class="section level2">
<h2>Bayesian Statistics - Introduction</h2>
<div id="introduction" class="section level3">
<h3>Introduction</h3>
<p>The role of probability distributions in Bayesian data analysis is to
represent uncertainty, and the role of Bayesian inference is to update
these probability distributions to reflect what has been learned from
data.</p>
<p>Let say I want to set an advertisement on social media. They claim, adds
on their surface has 10% of clicks. I a bit sceptical and asses probable
efectivnes may range between 0 and 0.20. I assume that binomial model
will imitate process generating visitors. Binomial model is my
generative model then.</p>
<pre class="r"><code>n_samples &lt;- 100000
n_ads_shown &lt;- 100
proportion_clicks &lt;- runif(n_samples, min = 0.0, max = 0.2)
n_visitors &lt;- rbinom(n = n_samples, size = n_ads_shown, prob = proportion_clicks)

par(mfrow=c(1,2))
# Visualize proportion clicks
hist(proportion_clicks)
# Visualize n_visitors
hist(n_visitors)</code></pre>
<p><img src="/blog/encyklopedia/3_Statistics_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<p>Below I present joint distribution over both the underlying proportion
of clicks and how many visitors I would get.</p>
<p><img src="/blog/encyklopedia/3_Statistics_files/figure-html/unnamed-chunk-8-1.png" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<p>I ran my ad campaign, and 13 people clicked and visited your site when
the ad was shown a 100 times. I would now like to use this new
information to update the Bayesian model. The reason that we call it
posterior is because it represents the uncertainty after (that is,
posterior to) having included the information in the data.</p>
<pre class="r"><code># Create the posterior data frame
posterior &lt;- prior[prior$n_visitors == 13, ]

# Visualize posterior proportion clicks - below I condition the joint distribution - of prior distribution of proportion_clicks and distribution of n_visitors 
hist(posterior$proportion_clicks)</code></pre>
<p><img src="/blog/encyklopedia/3_Statistics_files/figure-html/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<p>Now we want to use this updated proportion_clicks to predict how many
visitors we would get if we reran the ad campaign.</p>
<pre class="r"><code># Assign posterior to a new variable called prior
prior &lt;- posterior

# Take a look at the first rows in prior
head(prior)</code></pre>
<pre><code>##     proportion_clicks n_visitors
## 29          0.1554544         13
## 32          0.1233524         13
## 53          0.1892127         13
## 73          0.1170808         13
## 131         0.1713921         13
## 141         0.0867069         13</code></pre>
<pre class="r"><code># Replace prior$n_visitors with a new sample and visualize the result
n_samples &lt;-  nrow(prior)
n_ads_shown &lt;- 100
prior$n_visitors &lt;- rbinom(n_samples, size = n_ads_shown, prob = prior$proportion_clicks)
hist(prior$n_visitors)</code></pre>
<p><img src="/blog/encyklopedia/3_Statistics_files/figure-html/unnamed-chunk-10-1.png" width="672" style="display: block; margin: auto auto auto 0;" /></p>
</div>
<div id="priors" class="section level3">
<h3>Priors</h3>
<div id="beta-distribution" class="section level4">
<h4>Beta distribution</h4>
<p>The Beta distribution is a useful probability distribution when you want
model uncertainty over a parameter bounded between 0 and 1. Here you’ll
explore how the two parameters of the Beta distribution determine its
shape.</p>
<p>So the larger the shape parameters are, the more concentrated the beta
distribution becomes.</p>
<pre class="r"><code># Explore using the rbeta function
beta_1 &lt;- rbeta(n = 1000000, shape1 = 1, shape2 = 1)
beta_2 &lt;- rbeta(n = 1000000, shape1 = 100, shape2 = 100)
beta_3 &lt;- rbeta(n = 1000000, shape1 = 100, shape2 = 20)
beta_4 &lt;- rbeta(n = 1000000, shape1 = 5, shape2 = 95)



par(mfrow=c(2,2))
hist(beta_1, breaks=seq(0,1,0.02), main = &quot;shape1 = 1, shape2 = 1&quot;)
hist(beta_2, breaks=seq(0,1,0.02), main = &quot;shape1 = 100, shape2 = 100&quot;)
hist(beta_3, breaks=seq(0,1,0.02), main = &quot;shape1 = 100, shape2 = 20&quot;)
hist(beta_4, breaks=seq(0,1,0.02), main = &quot;shape1 = 5, shape2 = 95&quot;)</code></pre>
<p><img src="/blog/encyklopedia/3_Statistics_files/figure-html/unnamed-chunk-11-1.png" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<p>The 4th graphs represents the best following setence: <em>Most ads get
clicked on 5% of the time, but for some ads it is as low as 2% and for
others as high as 8%.</em></p>
</div>
</div>
<div id="contrasts-and-comparison" class="section level3">
<h3>Contrasts and comparison</h3>
<p>Let say, I initialize also text add campaign, get 6 visitors out of 100
views and now I want to compare which one video or text add is more cost
effective.</p>
<pre class="r"><code># Define parameters
n_draws &lt;- 100000
n_ads_shown &lt;- 100
proportion_clicks &lt;- runif(n_draws, min = 0.0, max = 0.2)
n_visitors &lt;- rbinom(n = n_draws, size = n_ads_shown, 
                     prob = proportion_clicks)
prior &lt;- data.frame(proportion_clicks, n_visitors)

# Create the posteriors for video and text ads
posterior_video &lt;- prior[prior$n_visitors == 13, ]
posterior_text &lt;- prior[prior$n_visitors == 6, ]

# Visualize the posteriors
hist(posterior_video$proportion_clicks, xlim = c(0, 0.25))</code></pre>
<p><img src="/blog/encyklopedia/3_Statistics_files/figure-html/unnamed-chunk-12-1.png" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<pre class="r"><code>hist(posterior_text$proportion_clicks, xlim = c(0, 0.25))</code></pre>
<p><img src="/blog/encyklopedia/3_Statistics_files/figure-html/unnamed-chunk-12-2.png" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<pre class="r"><code>posterior &lt;- data.frame(video_prop = posterior_video$proportion_clicks[1:4000],
                        text_prop = posterior_text$proportion_click[1:4000])

# Calculate the posterior difference: video_prop - text_prop
posterior$prop_diff &lt;- posterior$video_prop - posterior$text_prop 

# Visualize prop_diff
hist(posterior$prop_diff)</code></pre>
<p><img src="/blog/encyklopedia/3_Statistics_files/figure-html/unnamed-chunk-12-3.png" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<pre class="r"><code># Calculate the median of prop_diff
median(posterior$prop_diff)</code></pre>
<pre><code>## [1] 0.06513359</code></pre>
<pre class="r"><code># Calculate the proportion
mean(posterior$prop_diff &gt; 0.0)</code></pre>
<pre><code>## [1] 0.943</code></pre>
<pre class="r"><code>#Different adds have differnt costs then:
visitor_spend &lt;- 2.53
video_cost &lt;- 0.25
text_cost &lt;- 0.05

# Add the column posterior$video_profit
posterior$video_profit &lt;- posterior$video_prop * visitor_spend - video_cost

# Add the column posterior$text_profit
posterior$text_profit &lt;- posterior$text_prop * visitor_spend - text_cost

# Visualize the video_profit and text_profit columns
hist(posterior$video_profit)</code></pre>
<p><img src="/blog/encyklopedia/3_Statistics_files/figure-html/unnamed-chunk-12-4.png" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<pre class="r"><code>hist(posterior$text_profit)</code></pre>
<p><img src="/blog/encyklopedia/3_Statistics_files/figure-html/unnamed-chunk-12-5.png" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<pre class="r"><code># Add the column posterior$profit_diff
posterior$profit_diff &lt;- posterior$video_profit - posterior$text_profit

# Visualize posterior$profit_diff
hist(posterior$profit_diff)</code></pre>
<p><img src="/blog/encyklopedia/3_Statistics_files/figure-html/unnamed-chunk-12-6.png" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<pre class="r"><code># Calculate a &quot;best guess&quot; for the difference in profits
median(posterior$profit_diff)</code></pre>
<pre><code>## [1] -0.03521202</code></pre>
<pre class="r"><code># Calculate the probability that text ads are better than video ads
mean(posterior$profit_diff &lt; 0)</code></pre>
<pre><code>## [1] 0.646</code></pre>
<pre class="r"><code>#So it seems that the evidence does not strongly favor neither text nor video ads. But if forced to choose the text ads is better.</code></pre>
<div id="changeing-generative-model" class="section level4">
<h4>Changeing Generative model</h4>
<p>Company has changed the way how they price adds. Now they take money
just for full day of exposition. Binomial model, which approximate
participation of succes in all trials (click in all views) is no longer
valid. For new scenario. <strong>Poison distribution</strong> is now needed.</p>
<p><strong>The Poison distribution takes only one parameter which is the mean
number of events per time unit</strong></p>
<p>In R you can simulate from a Poisson distribution using rpois where
lambda is the average number of occurrences:</p>
<pre class="r"><code># Change the model according to instructions
n_draws &lt;- 100000
mean_clicks &lt;- runif(n_draws, min = 0, max = 80) #this is my prior
n_visitors &lt;- rpois(n = n_draws, mean_clicks)

prior &lt;- data.frame(mean_clicks, n_visitors)
posterior &lt;- prior[prior$n_visitors == 19, ]

hist(prior$mean_clicks)</code></pre>
<p><img src="/blog/encyklopedia/3_Statistics_files/figure-html/unnamed-chunk-13-1.png" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<pre class="r"><code>hist(posterior$mean_clicks)</code></pre>
<p><img src="/blog/encyklopedia/3_Statistics_files/figure-html/unnamed-chunk-13-2.png" width="672" style="display: block; margin: auto auto auto 0;" /></p>
</div>
</div>
<div id="dealing-with-2-parameter-model" class="section level3">
<h3>Dealing with 2 parameter model</h3>
<pre class="r"><code>#  the temperatures of Sweden water in 21 th of June in few following year
temp &lt;- c(19,23,20,17,23)
# Defining the parameter grid - here are are my priors about the posible values of parameters of distribution
pars &lt;- expand.grid(mu = seq(8,30, by = 0.5), 
                    sigma = seq(0.1, 10, by= 0.3))
# Defining and calculating the prior density for each parameter combination
pars$mu_prior &lt;- dnorm(pars$mu, mean = 18, sd = 5)
pars$sigma_prior &lt;- dunif(pars$sigma, min = 0, max = 10)
pars$prior &lt;- pars$mu_prior * pars$sigma_prior
# Calculating the likelihood for each parameter combination
for(i in 1:nrow(pars)) {
  likelihoods &lt;- dnorm(temp, pars$mu[i], pars$sigma[i])
  pars$likelihood[i] &lt;- prod(likelihoods)
}
# Calculate the probability of each parameter combination
pars$probability &lt;- pars$likelihood * pars$prior
pars$probability &lt;- pars$probability / sum(pars$probability )

library(lattice)
levelplot(probability ~ mu * sigma, data = pars)</code></pre>
<p><img src="/blog/encyklopedia/3_Statistics_files/figure-html/unnamed-chunk-14-1.png" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<p>What’s likely the average water temperature for this lake on 20th of
Julys, and what’s the probability the water temperature is going to be
18 or more on the next 20th?</p>
<p>Right now the posterior probability distribution is represented as a
data frame with one row per parameter combination with the corresponding
probability.</p>
<pre class="r"><code>head(pars)</code></pre>
<pre><code>##     mu sigma   mu_prior sigma_prior       prior likelihood probability
## 1  8.0   0.1 0.01079819         0.1 0.001079819          0           0
## 2  8.5   0.1 0.01312316         0.1 0.001312316          0           0
## 3  9.0   0.1 0.01579003         0.1 0.001579003          0           0
## 4  9.5   0.1 0.01880982         0.1 0.001880982          0           0
## 5 10.0   0.1 0.02218417         0.1 0.002218417          0           0
## 6 10.5   0.1 0.02590352         0.1 0.002590352          0           0</code></pre>
<p>But my questions are much easier to answer if the posterior is
represented as a large number of samples, like in earlier chapters. So,
let’s draw a sample from this posterior.</p>
<pre class="r"><code>sample_indices &lt;- sample(1:nrow(pars), size=10000, replace=TRUE, prob=pars$probability)
pars_sample &lt;- pars[sample_indices,c(&quot;mu&quot;,&quot;sigma&quot;)]
head(pars_sample)</code></pre>
<pre><code>##       mu sigma
## 476 20.5   3.1
## 252 21.0   1.6
## 919 17.0   6.1
## 524 22.0   3.4
## 746 20.5   4.9
## 697 18.5   4.6</code></pre>
<p>What is probabibility of temperature being 18 or above? Not mean
temperature, the actual temperature.</p>
<pre class="r"><code>#rnorm is vectorized and implicitly loops over mu and sigma
pred_temp&lt;- rnorm(10000, mean=pars_sample$mu, sd=pars_sample$sigma)

par(mfrow=c(1,2))
hist(pars_sample$mu,30, main = &#39;probability distribution of mean temperature&#39;)
hist(pred_temp,30, main = &#39;probability distribution of tempeture&#39; )</code></pre>
<p><img src="/blog/encyklopedia/3_Statistics_files/figure-html/unnamed-chunk-17-1.png" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<pre class="r"><code>mean(pred_temp&gt;=18)</code></pre>
<pre><code>## [1] 0.7272</code></pre>
</div>
<div id="automatisation---best-package" class="section level3">
<h3>Automatisation - BEST package</h3>
<p>The Bayesian model behind BEST assumes that the generative model for the
data is a t-distribution; a more flexible distribution than the normal
distribution as it assumes that data points might be outliers to some
degree. This makes BEST’s estimate of the mean difference robust to
outliers in the data.</p>
<p>The t-distribution is just like the normal distribution, a generative
model with a mean and a standard deviation that generates heap shaped
data. The difference is that the t-distribution has an extra parameter,
sometimes called the degrees-of-freedom parameter, that governs how
likely the t-distribution is to generate outliers far from its center.</p>
<p>Another way in which BEST is different is that BEST uses a so-called
Markov chain Monte Carlo method to fit the model. Markov chain Monte
Carlo, or MCMC for short, returns a table of samples from the posterior,
we can work with the output just like before.</p>
<pre class="r"><code># The IQ of zombies on a regular diet and a brain based diet.
iq_brains &lt;- c(44, 52, 42, 66, 53, 42, 55, 57, 56, 51)
iq_regular &lt;- c(55, 44, 34, 18, 51, 40, 40, 49, 48, 46)

# Calculate the mean difference in IQ between the two groups
mean(iq_brains) - mean(iq_regular)

# Fit the BEST model to the data from both groups
library(BEST)
library(rjags)
best_posterior &lt;- BESTmcmc(iq_brains, iq_regular)

# Plot the model result
plot(best_posterior)</code></pre>
<p>Assume that a super smart mutant zombie (IQ = 150) got into the
iq_regular group by mistake. This might mess up the results as you and
your colleagues really were interested in how diet affects normal
zombies.</p>
<pre class="r"><code># The IQ of zombies given a regular diet and a brain based diet.
iq_brains &lt;- c(44, 52, 42, 66, 53, 42, 55, 57, 56, 51)
iq_regular &lt;- c(55, 44, 34, 18, 51, 40, 40, 49, 48, 
                150) # &lt;- Mutant zombie

# Modify the data above and calculate the difference in means
mean(iq_brains) - mean(iq_regular)</code></pre>
<pre class="r"><code># Fit the BEST model to the modified data and plot the result
library(BEST)
best_posterior &lt;- BESTmcmc(iq_brains, iq_regular)
plot(best_posterior)</code></pre>
</div>
<div id="conclusions" class="section level3">
<h3>Conclusions</h3>
<p>Bayes allows you to tweak, change and tinker with the model to better
fit the data analytical problem you have. But a last reason to use Bayes
is because it is optimal, kind of. It can be shown, theoretically, that
no other method learns as efficiently from data as Bayesian inference.</p>
<p>In above examples I show what Bayesian model is about: * I describe my
expectations of proportion_clicks as uniform distribution (prior) *
Then i describe a generative model which will be responsible for
generating views based on proportion_clicks - the second source of
variability. For this aim I use two diffrent distribution - binomial and
poison - depending on specifity of exercise. * I was able to say which
add wass better, more, I was able to say which add was better in
probability way.</p>
</div>
</div>
<div id="bayesian-statistics---intermediate" class="section level2">
<h2>Bayesian Statistics - Intermediate</h2>
<div id="likelihood" class="section level3">
<h3>Likelihood</h3>
<p>On the example of poll. Imagine I am taking part in election to local
goverment. Based on many historical election poles I can count on 45% of
votes. Votes chances are approximate by bheta function.</p>
<pre class="r"><code>df&lt;-data.frame(sample=seq(0,1,0.01),
               density=dbeta(x=seq(0,1,0.01),shape1=45,shape2=55))
df %&gt;% ggplot(aes(x=sample,y=density))+
  geom_line()+
  ggtitle(&quot;Density function&quot;)</code></pre>
<p>Lets imagine that i receive 60% of votes in ellection pole. I can assume
that binomial distribution is well suited for generative model
responsible for how many votes I am geting. Then I may ask myself:
**How probable would be obtaining such a results (60%) of votes under
different succes_rate (paramter of Binomial distribution).</p>
<pre class="r"><code>df&lt;-data.frame(likelihood=dbinom(x=6,size=10,prob=seq(0,1,0.1)), 
               parameter_p=seq(0,1,0.1))

df %&gt;% ggplot(aes(x=parameter_p,y=likelihood))+
  geom_line()+
  ggtitle(&quot;Likelihood distribution over different succes_rate parameters&quot;)</code></pre>
<p>The likelihood function summarizes the likelihood of observing polling
data X under different values of the underlying support parameter p.
Thus, the likelihood is a function of p that depends upon the observed
data X</p>
</div>
<div id="posterior" class="section level3">
<h3>Posterior</h3>
<p>Since I’ve got the prior &amp; likelihood:</p>
<ul>
<li><p>prior: let say based on the historical pole % of votes I can count
on is described by betha distribution Betha(45.55) –&gt; most
probable is geting 45% votes</p></li>
<li><p>likelihood: is denoting to the most recent data shown above</p></li>
</ul>
<p>I can approach now to modeling <strong>posterior model of p</strong> According to
Bayes rules posterior is calculating by:</p>
<p><em>posterior</em> = prior * likelihood</p>
<p>However, in more sophisticated model settings, tidy, closed-form
solutions to this formula might not exist. Very loosely speaking, the
goal here is to send information out to the JAGS program, which will
then design an algorithm to sample from the posterior, based on which I
will then simulate the posterior.</p>
<div id="compiling-rjags-model" class="section level4">
<h4>Compiling rjags model</h4>
<p>Built from previous polls &amp; election data, my prior model of is a
Beta(,) with shape parameters a=45 and b=55. For added insight into
<strong>p</strong>, I also polled potential voters. The dependence of X, the number
of these voters that support you, on <strong>p</strong> is modeled by the
Bin(<strong>n</strong>,<strong>p</strong>) distribution.</p>
<p>In the completed poll, X=6 of n=10 voters supported you. The next goal
is to update my model of in light of these observed polling data! To
this end, I will use the rjags package to approximate the posterior
model of . This exercise will be break down into the 3 rjags steps:
define, compile, simulate.</p>
<pre class="r"><code>library(rjags)

# DEFINE the model
vote_model &lt;- &quot;model{
    # Likelihood model for X
    X ~ dbin(p, n)
    
    # Prior model for p
    p ~ dbeta(a, b)
}&quot;

# COMPILE the model    
vote_jags &lt;- jags.model(textConnection(vote_model), 
    data = list(a = 45, b = 55, X = 6, n = 10),
    inits = list(.RNG.name = &quot;base::Wichmann-Hill&quot;, .RNG.seed = 100))

# SIMULATE the posterior
vote_sim &lt;- coda.samples(model = vote_jags, variable.names = c(&quot;p&quot;), n.iter = 10000)

# PLOT the posterior
plot(vote_sim, trace = FALSE)</code></pre>
</div>
</div>
</div>


<footer class="footline">
	
</footer>

        
        </div>
        

      </div>

    <div id="navigation">
        
        

        
            
            
                
                    
                    
                
                

                    
                    
                        
                    
                    

                    
                        
            
            
                
                    
                    
                
                

                    
                    
                    

                    
                        
            
            
                
                    
                        
                        
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
                    
                        
            
            
                
                    
                        
                        
                    
                
                

                    
                    
                    

                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
                    
            
        

        


	 
	 
		
			<a class="nav nav-prev" href="/blog/encyklopedia/2_data_grapling/" title="Data Exploration"> <i class="fa fa-chevron-left"></i></a>
		
		
			<a class="nav nav-next" href="/blog/projects/" title="Projects" style="margin-right: 0px;"><i class="fa fa-chevron-right"></i></a>
		
	
    </div>

    </section>

    <div style="left: -1000px; overflow: scroll; position: absolute; top: -1000px; border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;">
      <div style="border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;"></div>
    </div>
    <script src="/blog/js/clipboard.min.js?1640713644"></script>
    <script src="/blog/js/perfect-scrollbar.min.js?1640713644"></script>
    <script src="/blog/js/perfect-scrollbar.jquery.min.js?1640713644"></script>
    <script src="/blog/js/jquery.sticky.js?1640713644"></script>
    <script src="/blog/js/featherlight.min.js?1640713644"></script>
    <script src="/blog/js/highlight.pack.js?1640713644"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="/blog/js/modernizr.custom-3.6.0.js?1640713644"></script>
    <script src="/blog/js/learn.js?1640713644"></script>
    <script src="/blog/js/hugo-learn.js?1640713644"></script>
    
        
            <script src="/blog/mermaid/mermaid.js?1640713644"></script>
        
        <script>
            mermaid.initialize({ startOnLoad: true });
        </script>
    
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-105947713-1', 'auto');
  ga('send', 'pageview');

</script>
  </body>
</html>

